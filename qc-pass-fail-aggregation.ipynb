{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup dependencies, install metric parser\n",
    "import sys\n",
    "!{sys.executable} -m pip install --no-cache-dir --upgrade  qc-metric-aggregator\n",
    "\n",
    "import os\n",
    "import firecloud.api as fapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up constants\n",
    "bucket = os.environ['WORKSPACE_BUCKET']\n",
    "workspace_namespace = os.environ['WORKSPACE_NAMESPACE']\n",
    "workspace_name = os.environ['WORKSPACE_NAME']\n",
    "threshold_file_name = \"thresholds.yml\"\n",
    "final_output_file_name = \"qc_results.tsv\"\n",
    "\n",
    "#we should pull this from a central place rather than a workspace specific bucket\n",
    "master_thresholds_file = bucket + \"/\" + threshold_file_name\n",
    "#copy the thresholds file to the notebook env\n",
    "!gsutil cp $master_thresholds_file ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch sample ids from the terra workspace table\n",
    "samples = fapi.get_entities(workspace_namespace, workspace_name, \"sample\").json()\n",
    "sample_ids = [s['name'] for s in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure out which files from cromwell runs we need to localize\n",
    "#this heuristic can definitely be futher optimized\n",
    "files_in_bucket = !gsutil ls -r $bucket/**\n",
    "files_to_localize = [f for f in files_in_bucket if any(sample_id in f for sample_id in sample_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create input file for gsutil file localization\n",
    "with open('files_to_localize', 'w') as fout:\n",
    "    fout.write(\"\\n\".join(files_to_localize))\n",
    "\n",
    "!mkdir localized_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the metric aggregator for each sample and write out the results\n",
    "from process_metrics.threshold_file_parser import ThresholdFileParser\n",
    "from process_metrics.qc_validator import QcValidator\n",
    "from process_metrics.metrics import AvailableMetrics\n",
    "from process_metrics.report_generator import ReportGenerator\n",
    "\n",
    "pass_fail_thresholds = ThresholdFileParser(threshold_file_name).thresholds()\n",
    "\n",
    "qc_results = []\n",
    "first_sample = True\n",
    "with open(final_output_file_name, 'w') as fout:   \n",
    "    for sample_id in sample_ids:\n",
    "        \n",
    "        #localize files relevant to this sample\n",
    "        !cat files_to_localize | grep $sample_id | grep -v .cram | gsutil -m cp -I ./localized_files\n",
    "        \n",
    "        metrics = AvailableMetrics(sample_id)\n",
    "        validator = QcValidator(\"localized_files/\")\n",
    "        res = ReportGenerator(sample_id, pass_fail_thresholds, metrics, validator).gather_metrics()\n",
    "        headers = res[0]\n",
    "        values = res[1]\n",
    "        if first_sample:\n",
    "            first_sample = False\n",
    "            headers[0] = \"entity:qc_result_sample_id\"\n",
    "            lowercased_headers = [h.lower() for h in headers]\n",
    "            print(str.join(\"\\t\", lowercased_headers), file=fout)\n",
    "        print(str.join(\"\\t\", values), file=fout)\n",
    "        \n",
    "        #clean up localized files for this sample\n",
    "        !rm -rf localized_files/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the results into terra as a datatable\n",
    "fapi.upload_entities_tsv(workspace_namespace, workspace_name, final_output_file_name, \"flexible\")\n",
    "\n",
    "#copy the TSV to the workspace bucket\n",
    "uploaded_tsv = bucket + '/' + final_output_file_name\n",
    "!gsutil cp $final_output_file_name $uploaded_tsv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
